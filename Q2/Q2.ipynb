{"cells":[{"cell_type":"markdown","metadata":{"id":"5FSxPWUPLYq4"},"source":["**name: mahshad moradi** \\\n","**std number: 400109373**"]},{"cell_type":"markdown","metadata":{"id":"PA_zmwKPCs9Q"},"source":["\n","\n","---\n","\n","# Supervised Network training with the Forward-Forward algorithm"]},{"cell_type":"markdown","metadata":{"id":"6vL7F-sclVj7"},"source":["Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDNHY0kRiulP"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from tqdm import tqdm\n","from torch.optim import Adam\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"4zXYLFdXi0TP"},"source":[" Load MNIST dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZupLBqSjawq"},"outputs":[],"source":["def MNIST_loaders(train_batch_size=50000, test_batch_size=10000):\n","    \"\"\"\n","    Provides PyTorch data loaders for the MNIST dataset.\n","    \"\"\"\n","    transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,)), Lambda(lambda x: torch.flatten(x))])\n","\n","    train_loader = DataLoader(MNIST('./data/', train=True, download=True, transform=transform), batch_size=train_batch_size, shuffle=True)\n","\n","    test_loader = DataLoader(MNIST('./data/', train=False, download=True, transform=transform), batch_size=test_batch_size, shuffle=False)\n","\n","    return train_loader, test_loader"]},{"cell_type":"markdown","metadata":{"id":"2uhjiHIWJVD9"},"source":["Layer as a subb-class of torch.nn.Linear that uses the FF algorithm in the training of the layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8lRh-q89FY_"},"outputs":[],"source":["class Layer(nn.Linear):\n","\n","    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n","        super().__init__(in_features, out_features, bias, device, dtype)\n","        self.relu = torch.nn.ReLU()\n","        # Adam optimizer with a learning rate of 0.03\n","        self.opt = Adam(self.parameters(), lr=0.03)\n","        # Threshold for positive and negative samples\n","        self.threshold = 2.0\n","        self.num_epochs = 1000\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through the layer.\n","        \"\"\"\n","        # normalizing the previous layer output\n","        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n","        # the relu output of the layer\n","        return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0))\n","\n","    def train(self, x_pos, x_neg):\n","        \"\"\"\n","        Train the layer on positive and negative examples.\n","        \"\"\"\n","        for i in tqdm(range(self.num_epochs)):\n","            # from the Goodness description\n","            g_pos = self.forward(x_pos).pow(2).mean(1)\n","            g_neg = self.forward(x_neg).pow(2).mean(1)\n","            # forwarding both the positive and negative data\n","            loss = torch.log(1 + torch.exp(torch.cat([self.threshold - g_pos , g_neg - self.threshold]))).mean()\n","            # optimization\n","            self.opt.zero_grad()\n","            loss.backward() #computing the derivatives\n","            self.opt.step()\n","        return self.forward(x_pos).detach(), self.forward(x_neg).detach()"]},{"cell_type":"markdown","metadata":{"id":"JNq3NZfM9XmD"},"source":["The loss function $loss = mean(log(1 + exp[(threshold−positivedata),(negativedata−threshold)]))$ is designed to encourage positive samples to have values larger than the threshold and negative samples to have values smaller than the threshold as we wanted.\n","\n","- **Positive Samples : the term $e^{(Threshold - PositiveData)}$:** This term encourages positive samples to have values larger than the threshold and amplifies their difference being exponential. If the model predicts a positive sample with a value significantly lower than the threshold, the loss will be high.\n","\n","- **Negative Samples : the term $e^{(NegativeData - Threshold)}$:** This term encourages negative samples to have values smaller than the threshold and amplifies their difference being exponential. If the model predicts a negative sample with a value significantly higher than the threshold, the loss will be high.\n","\n","**Overall Interpretation:** The loss function penalizes the model when it misplaces positive and negative samples relative to the specified threshold. It utilizes the logistic function and logarithm to provide a smooth and differentiable measure of how well the model is separating positive and negative samples around the threshold. The mean operation ensures that the loss is averaged across all samples, normalizing it for effective training of neural networks.\n"]},{"cell_type":"markdown","metadata":{"id":"I6cE1y95EHmV"},"source":["Network class with module attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOY76pTvJUCz"},"outputs":[],"source":["class Net(torch.nn.Module):\n","\n","    def __init__(self, dims):\n","        super(Net, self).__init__()\n","        # constructing the network layers according to layer dimensions\n","        self.layers = []\n","        for d in range(len(dims) - 1):\n","            self.layers += [Layer(dims[d], dims[d + 1]).cuda()]\n","\n","    def predict(self, x):\n","        \"\"\"\n","        Make predictions using the trained network.\n","        \"\"\"\n","        goodness_per_label = []\n","        # Iterate over labels\n","        for label in range(10):\n","            # h is the output of layers of the network\n","            layer_output = overlay_labels_on_data(x, label)\n","            goodness = []\n","            for layer in self.layers:\n","                # layer output and Goodness calculations\n","                layer_output = layer.forward(layer_output)\n","                goodness += [layer_output.pow(2).mean(1)]\n","            goodness_per_label += [sum(goodness).unsqueeze(1)]\n","        # Combine goodness values for each label\n","        goodness_per_label = torch.cat(goodness_per_label, 1)\n","        # Choose the label with the highest goodness\n","        return goodness_per_label.argmax(1)\n","\n","    def train(self, x_pos, x_neg):\n","        \"\"\"\n","        Train the network on positive and negative data.\n","        \"\"\"\n","        h_pos, h_neg = x_pos, x_neg\n","        for i, layer in enumerate(self.layers):\n","            print('training layer', i)\n","            h_pos, h_neg = layer.train(h_pos, h_neg)"]},{"cell_type":"markdown","metadata":{"id":"ToANlDC4XbzR"},"source":["The method \"predict\" doeas the prediction of the test data as explained bellow for each sample of it :  \n","After training with FF, classifying a test digit involves a single forward pass through the network using an input comprising the test digit and a neutral label (ten entries of 0.1). The hidden activities in all layers except the first hidden layer are then used as inputs to a softmax learned during training. While this is a quick but sub-optimal method for image classification, a more effective approach is to run the network with a specific label as part of the input. The goodness values of all but the first hidden layer are accumulated for each label separately. Finally, the label with the highest accumulated goodness is chosen, providing a more informed and nuanced classification decision."]},{"cell_type":"markdown","metadata":{"id":"34gikfQyvwgW"},"source":["Data creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vlad0QqQvzJo"},"outputs":[],"source":["def overlay_labels_on_data(data_matrix, label_indices):\n","    \"\"\"\n","    Replaces the first 10 pixels of each data sample with a one-hot-encoded label.\n","    \"\"\"\n","    modified_data = data_matrix.clone()\n","    modified_data[:, :10].fill_(0.0)\n","\n","    # Overlay one-hot-encoded labels on the data matrix\n","    modified_data[range(data_matrix.shape[0]), label_indices] = data_matrix.max()\n","\n","    return modified_data"]},{"cell_type":"markdown","metadata":{"id":"wC26iWTfxCpc"},"source":["Creating the model and evaluating its results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7o-T5oS2jFyO","outputId":"16a91ac0-5475-46c0-ad06-73add02baabc"},"outputs":[{"name":"stdout","output_type":"stream","text":["training layer 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [01:05<00:00, 15.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["training layer 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:40<00:00, 24.44it/s]\n"]}],"source":["train_loader, test_loader = MNIST_loaders()\n","\n","net = Net([784, 500, 500])\n","x, y = next(iter(train_loader))\n","x, y = x.cuda(), y.cuda()\n","\n","# creating positive data\n","x_pos = overlay_labels_on_data(x, y)\n","rnd = torch.randperm(x.size(0))\n","# creating negative data using wrong lables\n","x_neg = overlay_labels_on_data(x, y[rnd])\n","\n","# training the model\n","net.train(x_pos, x_neg)"]},{"cell_type":"markdown","metadata":{"id":"WLSLBgA0nOes"},"source":["The evaluation results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c5Kvz-mnItc","outputId":"0a1a4e7b-1030-4ac0-b583-44b9ec7b3a4f"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \n","train accuracy : 0.9275799989700317\n","train error: 0.07242000102996826\n","test accuracy : 0.9275799989700317\n","test error: 0.07160001993179321\n"]}],"source":["print(' ')\n","\n","train_accuracy = net.predict(x).eq(y).float().mean().item()\n","print('train accuracy :', train_accuracy)\n","print('train error:', 1.0 - train_accuracy)\n","\n","# the test data\n","x_test, y_test = next(iter(test_loader))\n","x_test, y_test = x_test.cuda(), y_test.cuda()\n","\n","test_accuracy = net.predict(x_test).eq(y_test).float().mean().item()\n","print('test accuracy :', train_accuracy)\n","print('test error:', 1.0 - test_accuracy )"]},{"cell_type":"markdown","metadata":{"id":"RvquDUsAVtC-"},"source":["\n","\n","---\n","\n","# Unsupervised Network training with the Forward-Forward algorithm"]},{"cell_type":"markdown","metadata":{"id":"z0eEouxxHPno"},"source":["Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AI9sqfOFHOPn"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from matplotlib import pyplot as plt\n","from scipy.signal import convolve2d\n","from torch import tensor, Tensor\n","import torchvision\n","from tqdm import tqdm\n","import os\n","from sklearn.metrics import accuracy_score\n","from torch.optim import Adam\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n","from torch.utils.data import DataLoader\n","import scipy.ndimage\n","import random\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"pQgLrIubmkcl"},"source":["Negative data creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cv8Gbo4D7hjq"},"outputs":[],"source":["# for generating neg data using random samples of pos data\n","def make_random_pairs(length):\n","  tmp = np.random.randint(length, size=[length, 2])\n","  random_arr = [(row[0], row[1]) for row in tmp]\n","  return random_arr\n","\n","def neg_data_loader(num=-1):\n","    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","\n","    # Load the train MNIST dataset\n","    train_dataset = torchvision.datasets.MNIST(root=\"./\", train=True, transform=transform, download=True)\n","\n","    if num == -1:\n","      num = len(train_dataset)\n","    # make random pairs of train dataset\n","    random_pairs = make_random_pairs(num)\n","\n","    # Transform the data\n","    transformed_dataset = []\n","    for pair in random_pairs:\n","        image1 = train_dataset[pair[0]][0].squeeze()\n","        image2 = train_dataset[pair[1]][0].squeeze()\n","        mask = create_mask((image_1.shape[0], image_1.shape[1]))\n","        transformed_dataset.append(torch.add(torch.mul(image_1, mask), torch.mul(image_2, 1 - mask)).type(torch.float32))\n","\n","    return transformed_dataset\n","\n","# create mask for a given shape\n","def create_mask(shape):\n","    blur_filter_1 = np.array(((0, 0, 0), (1/4, 1/2, 1/4), (0, 0, 0)))\n","    blur_filter_2 = blur_filter_1.T\n","\n","    # Create a random binary image\n","    image = np.random.randint(0, 2, size=shape)\n","\n","    # Blur the image with the specified filter\n","    for i in range(10):\n","        image = np.abs(convolve2d(image, blur_filter_1, mode='same'))\n","        image = np.abs(convolve2d(image, blur_filter_2, mode='same'))\n","\n","    # Binarize the blurred image\n","    mask = np.round(image).astype(np.uint8)\n","\n","    return tensor(mask)"]},{"cell_type":"markdown","metadata":{"id":"5jOlm8k5QWJ7"},"source":["Sample of negative data creation using implemented mask as explained in the paper"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":580},"executionInfo":{"elapsed":874,"status":"ok","timestamp":1700569755931,"user":{"displayName":"Sarah Moradi","userId":"00949342344843883065"},"user_tz":-210},"id":"ZJAJZp4oQEuV","outputId":"6cd8c33b-a76f-42a8-f5a7-4d902332117e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 136418469.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 37690010.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 124250218.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 21167254.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-78b63cb0ff54>:8: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n","  image_1 = torch.as_tensor(np.asarray(image_1))\n"]},{"data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the MNIST dataset\n","mnist = torchvision.datasets.MNIST(root='data/', download=True)\n","\n","# Get the first instance of the digit 1\n","image_1, _ = mnist[np.random.randint(len(mnist))]\n","image_2, _ = mnist[np.random.randint(len(mnist))]\n","\n","image_1 = torch.as_tensor(np.asarray(image_1))\n","image_2 = torch.as_tensor(np.asarray(image_2))\n","\n","mask = create_mask((28, 28))\n","image = torch.add(torch.mul(image_1, mask), torch.mul(image_2, 1 - mask))\n","\n","plt.figure()\n","\n","# Create the subplot\n","fig, ax = plt.subplots(1, 5)\n","images = [image_1, mask, image, 1 - mask, image_2]\n","names = [\"image_1\", \"mask\", \"image\", \"1-mask\", \"image_2\"]\n","# Add the images to the subplot\n","ax[0].imshow(image_1, cmap='gray')\n","ax[0].axis(\"off\")\n","ax[0].set_title(\"image 1\")\n","ax[1].imshow(mask, cmap='gray')\n","ax[1].axis(\"off\")\n","ax[1].set_title(\"mask\")\n","ax[2].imshow(image, cmap='gray')\n","ax[2].axis(\"off\")\n","ax[2].set_title(\"output\")\n","ax[3].imshow(1 - mask, cmap='gray')\n","ax[3].axis(\"off\")\n","ax[3].set_title(\"1 - mask\")\n","ax[4].imshow(image_2, cmap='gray')\n","ax[4].axis(\"off\")\n","ax[4].set_title(\"image 2\")\n","\n","# Show the subplot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"j3PY-3awNadk"},"source":["Negative data is generated by crafting a mask that includes substantial regions of ones and zeros. In the next step we create hybrid images for the negative dataset by combining one digit image with the mask and another digit image with the reverse of the mask, as depicted above as a sample. These masks are generated by initially using a random bit image and repeatedly applying blurring with a filter of [1/4, 1/2, 1/4] in both horizontal and vertical directions. After multiple blurring iterations, the image is then thresholded at 0.5."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":971,"status":"ok","timestamp":1700574017076,"user":{"displayName":"Sarah Moradi","userId":"00949342344843883065"},"user_tz":-210},"id":"sF7ZimfSy_B_"},"outputs":[],"source":["# forward forward layer class which is linear\n","class FF_Layer(nn.Linear):\n","    def __init__(self, in_features, out_features, n_epochs, bias, device):\n","        super().__init__(in_features, out_features, bias=bias)\n","        self.n_epochs = n_epochs\n","        self.opt = torch.optim.Adam(self.parameters())\n","        self.to(device)\n","        self.ln_layer = nn.LayerNorm(normalized_shape=[1, out_features]).to(device)\n","\n","    def forward(self, input):\n","        input = super().forward(input)\n","        input = self.ln_layer(input.detach())\n","        return input\n","\n","    # learn the weights of this linear function\n","    def learn(self, pos_acts, neg_acts):\n","        self.opt.zero_grad()\n","        goodness = self.goodness_score(pos_acts, neg_acts)\n","        goodness.backward()\n","        self.opt.step()\n","\n","    def goodness_score(self, pos_acts, neg_acts, threshold=2):\n","        \"\"\"\n","        The goodness score is calculated by summing up the positive and negative goodness values.\n","        This score is the actual quantity that undergoes optimization, not the goodness values themselves.\n","        The goodness values, in essence, refer to the same underlying metric, but they do not include the subtraction of a threshold.\n","        In other words, the goodness score represents the combined impact of positive and negative factors, while the goodness values\n","        without the threshold subtraction provide a measure of the inherent quality without the influence of a specific threshold.\n","        \"\"\"\n","        pos_goodness = -torch.sum(torch.pow(pos_acts, 2)) + threshold\n","        neg_goodness = torch.sum(torch.pow(neg_acts, 2)) - threshold\n","        return torch.add(pos_goodness, neg_goodness)\n","\n","# main model\n","class UsNet(nn.Module):\n","    def __init__(self, n_epochs, n_layers=12, input_size = 28 * 28, n_neurons=2048,\n","                 bias = True, n_hid_to_log=3, n_classes=10, device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n","        super().__init__()\n","        self.n_hid_to_log = n_hid_to_log\n","        self.n_epochs = n_epochs\n","        self.device = device\n","        self.ff_layers = [FF_Layer(in_features=input_size, out_features=n_neurons, n_epochs=n_epochs, bias=bias, device=device)]\n","        for idx in range(n_layers - 1):\n","          self.ff_layers.append(FF_Layer(in_features=n_neurons, out_features=n_neurons, n_epochs=n_epochs, bias=bias, device=device))\n","        self.last_layer = nn.Linear(in_features=n_neurons * n_hid_to_log, out_features=n_classes, bias=bias)\n","        self.softmax = nn.Softmax()\n","        self.to(device)\n","        self.opt = torch.optim.Adam(self.last_layer.parameters())\n","\n","    def train_with_datasets(self, pos_dataloader, neg_dataloader):\n","        self.train()\n","        self.train_ff_layers(pos_dataloader, neg_dataloader)\n","        self.train_last_layer(pos_dataloader)\n","\n","\n","    def train_ff_layers(self, pos_dataloader, neg_dataloader):\n","        \"\"\"\n","        train the ff layers separately\n","        it uses goodness score to classify pos and neg data\n","        \"\"\"\n","        for epoch in tqdm(range(self.n_epochs), desc=\"FF Layers training\", position=0):\n","            for (pos_imgs, _), neg_imgs in zip(pos_dataloader, neg_dataloader):\n","                pos_acts = torch.reshape(pos_imgs, (pos_imgs.shape[0], 1, -1)).to(self.device)\n","                neg_acts = torch.reshape(neg_imgs, (neg_imgs.shape[0], 1, -1)).to(self.device)\n","                for layer in self.ff_layers:\n","                    pos_acts = layer(pos_acts)\n","                    neg_acts = layer(neg_acts)\n","                    layer.learn(pos_acts, neg_acts)\n","\n","    def train_last_layer(self, dataloader):\n","        \"\"\"\n","        this function use supervised learning to label each data(which is positive data), it uses softmax function and then\n","        crossentropy loss for classifying the datas.\n","        \"\"\"\n","        best_weights = self.state_dict()\n","        min_loss = float('inf')\n","        loss_module = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n","        for epoch in tqdm(range(self.n_epochs), desc=\"Last Layer training\", position=0):\n","            epoch_loss = 0\n","            for images, labels in dataloader:\n","                images = images.to(self.device)\n","                labels = labels.to(self.device)\n","                self.opt.zero_grad()\n","                preds = self(images)\n","                loss = loss_module(preds, labels)\n","                epoch_loss += loss\n","                loss.backward()\n","                self.opt.step()\n","            if min_loss > epoch_loss:\n","                min_loss = epoch_loss\n","                best_weights = self.state_dict()\n","        self.load_state_dict(best_weights)\n","\n","    def forward(self, image):\n","        image = image.to(self.device)\n","        image = torch.reshape(image, (image.shape[0], 1, -1))\n","        concat_output = []\n","        for idx, layer in enumerate(self.ff_layers):\n","            image = layer(image)\n","            if idx > len(self.ff_layers) - self.n_hid_to_log - 1:\n","                concat_output.append(image)\n","        concat_output = torch.concat(concat_output, 2)\n","        logits = self.last_layer(concat_output)\n","        return logits.squeeze()\n","\n","    def evaluate(self, dataloader):\n","        \"\"\"\n","        calculate the accuracy of the model on the given dataloader.\n","        \"\"\"\n","        self.eval()\n","        correct = 0\n","        for images, labels in tqdm(dataloader, desc=f\"Evaluating model\", position=0):\n","            images = images.to(self.device)\n","            labels = labels.to(self.device)\n","            preds = self(images)\n","            preds = torch.argmax(preds, 1)\n","            preds = Tensor.numpy(preds, force=True)\n","            labels = Tensor.numpy(labels, force=True)\n","            correct += np.sum(preds == labels)\n","        acc = correct / len(dataloader.dataset)\n","        return acc"]},{"cell_type":"markdown","metadata":{"id":"n2Yad7uX3pbX"},"source":["Initially, the system learns to transform input vectors into representation vectors without utilizing any information about the associated labels. In this phase, the focus is on capturing inherent patterns and structures within the data without explicit guidance from labeled examples.\n","\n","Subsequently, the model learns a simple linear transformation (Linear classifier) of these representation vectors into vectors of logits. Logits are unnormalized values that serve as inputs to a softmax function. The softmax function then computes a probability distribution over labels based on these logits.\n","\n","The combination of unsupervised learning for feature extraction and supervised learning for the linear transformation creates a comprehensive model capable of both capturing complex data representations and making informed predictions based on labeled information."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":405263,"status":"ok","timestamp":1700574883440,"user":{"displayName":"Sarah Moradi","userId":"00949342344843883065"},"user_tz":-210},"id":"Q289sEfN3UeD","outputId":"fe0ee520-0ebb-4860-9526-e2db3d681b36"},"outputs":[{"name":"stderr","output_type":"stream","text":["FF Layers training: 100%|██████████| 10/10 [03:41<00:00, 22.16s/it]\n","Last Layer training: 100%|██████████| 10/10 [01:37<00:00,  9.72s/it]\n","Evaluating model: 100%|██████████| 938/938 [00:10<00:00, 90.00it/s]\n","Evaluating model: 100%|██████████| 157/157 [00:01<00:00, 94.86it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","train dataset scores: \n"," accuracy: 90.58666666666667%, error: 0.09413333333333329\n","test dataset scores: \n"," accuracy: 90.07%, error: 0.09930000000000005\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["neg_dataset = neg_data_loader()\n","\n","# Load the MNIST dataset\n","transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","pos_dataset = torchvision.datasets.MNIST(root='./', download=True, transform=transform, train=True)\n","\n","# Create the data loader\n","pos_dataloader = DataLoader(pos_dataset, batch_size=64, shuffle=True)\n","\n","# Create the data loader\n","neg_dataloader = DataLoader(neg_dataset, batch_size=64, shuffle=True)\n","\n","# Create the test data loader\n","test_dataloader = DataLoader(torchvision.datasets.MNIST(root='./', train=False, download=False, transform=transform),\n","                             batch_size=64, shuffle=True)\n","\n","usNet = UsNet(n_epochs=10)\n","\n","usNet.train_with_datasets(pos_dataloader, neg_dataloader)\n","train_acc = usNet.evaluate(pos_dataloader)\n","test_acc = usNet.evaluate(test_dataloader)\n","\n","\n","print(f\"\\ntrain dataset scores: \\n accuracy: {train_acc * 100}%, error: {1 - train_acc}\" )\n","print(f\"test dataset scores: \\n accuracy: {test_acc * 100}%, error: {1 - test_acc}\" )"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
